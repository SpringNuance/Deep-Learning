{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3587c25",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f64f121ea92b253fbeb084612d9b9bf",
     "grade": false,
     "grade_id": "cell-e386151da4e377e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Deadline:</b> May 10, 2023 (Wednesday) 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 1. Denoising Diffusion Probabilistic Models (DDPM)\n",
    "\n",
    "The goal of this exercise is to get familiar with diffusion-based generative models using the DDPM model as an example. The model is proposed in [this paper](https://arxiv.org/pdf/2006.11239.pdf).\n",
    "\n",
    "**This exercise requires a significant amount of computing power, you need to use a GPU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c4e80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d4d4f67",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8306fc1764cffda16ae1151137725b78",
     "grade": true,
     "grade_id": "cell-6ab448c431e2040e",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# During evaluation, this cell sets skip_training to True\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m# skip_training = True\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtools\u001b[39;00m\u001b[39m,\u001b[39m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m      5\u001b[0m warnings\u001b[39m.\u001b[39mshowwarning \u001b[39m=\u001b[39m tools\u001b[39m.\u001b[39mcustomwarn\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tools'"
     ]
    }
   ],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True\n",
    "\n",
    "import tools, warnings\n",
    "warnings.showwarning = tools.customwarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8191e7b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fd'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12084\\3514777053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fd'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.utils as utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd60c6f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tools' has no attribute 'select_data_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12084\\1686829770.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# When running on your own computer, you can specify the data directory by:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# data_dir = tools.select_data_dir('/your/local/data/directory')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_data_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tools' has no attribute 'select_data_dir'"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302151b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "device = torch.device('cpu')\n",
    "#device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b50a071",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1d998f0bcbe98cf335ea02faf3d5c94d",
     "grade": false,
     "grade_id": "cell-c851c04eff89d9a1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016061e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "379aad03999fb88510b317bd4f0874d6",
     "grade": false,
     "grade_id": "cell-c79631d312e26acf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "In this exercise, we use standard MNIST data. To simplify the construction of the denoising model (U-net), we upscale the images to $32\\times 32$ resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25194dbf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcc41187e1cd1540b7e23c576970fffe",
     "grade": false,
     "grade_id": "cell-ec611ba9ba5acc48",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "#trainset = datasets.MNIST(root='../data/', train=True, download=True, transform=transform,)\n",
    "trainset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f9ab5d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d4d627248fdfbd071f1baacabf6b221e",
     "grade": false,
     "grade_id": "cell-cbe7fa2de968ac1e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "print(images.shape)\n",
    "tools.show_images(images[:8], ncol=4, cmap='binary', clim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560de9c1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ca46671d3eb4a6442ae376d164fdfe3e",
     "grade": false,
     "grade_id": "cell-f5f8145f88340f22",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Diffusion model\n",
    "\n",
    "In DDPM, the forward process (or diffusion process) is a Markov chain that gradually adds Gaussian noise to the data according to a variance schedule $\\beta_1, ..., \\beta_T$:\n",
    "$$\n",
    "q(x_{1:T} | x_0) = \\prod^T_{t=1} q(x_t|x_{t−1}), q(x_t|x_{t−1}) = N (x_t; \\sqrt{1 − \\beta_t} x_{t−1}, \\beta_t I)\n",
    "$$\n",
    "\n",
    "* In our implementation of DDPM, we use a linear schedule for $\\beta_t$ that grows linearly from 0.0001 to 0.02 with T=1000 time steps in total. Please store the values of $\\beta_t$ in attribute `self.betas`.\n",
    "\n",
    "* We implement the forward diffusion process in function `forward()`. This function receives a clearn sample $x_0$ and a noise instance $\\epsilon_t$ and returns\n",
    "$$\n",
    "x_t = \\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon_t\n",
    "$$\n",
    "which is a sample from the following distribution:\n",
    "$$\n",
    "q(x_t|x_0) = N(x_t; \\sqrt{\\bar{\\alpha}_t} x_{0}, (1 - \\bar{\\alpha}_t) I)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\bar{\\alpha}_t = \\prod^t_{s=1} \\alpha_s\n",
    "\\qquad\n",
    "\\alpha_t = 1 − \\beta_t.\n",
    "$$\n",
    "Note that the denoising model is trained to predict the noise instance $\\epsilon_t$ which is why we create it outside of the function.\n",
    "\n",
    "* Samples are generated with an inverse diffusion process which we implement in function `sample()`. The sampling process is described in Algorithm 2 of the paper:\n",
    "<img src=\"alg_sampling.png\" width=350>\n",
    "where $\\sigma_t = \\sqrt{\\beta_t}$.\n",
    "\n",
    "Notes:\n",
    "* **In this exercise, we do not condition our generative model on the class information (the classes of digits). Therefore, we expect argument `labels` to be `None`. If you are interested in playing with a generative model conditioned on the class information, you can write your code to support this scenario. We expect no conditioning on classes in the grading tests.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba55b4",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cfe18695becaac521ec640b873549d8c",
     "grade": false,
     "grade_id": "cell-0a7364f703aa000f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Diffusion(nn.Module):\n",
    "    \"\"\"Diffusion model with a linear schedule of the temperatures.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_timesteps=1000):\n",
    "        super().__init__()\n",
    "\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x, t, noise=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, ...): Input samples.\n",
    "          t of shape (batch_size,): Corruption temperatures.\n",
    "          noise of shape (batch_size, ...): Noise instanses used for corruption.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, model, x_shape, labels=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          model: A denoising model. model(x, t, labels) takes as inputs:\n",
    "                   x of shape (batch_size, n_channels, H, W): corrupted examples.\n",
    "                   t of shape (batch_size,): LongTensor of time steps.\n",
    "                   labels of shape (batch_size,): LongTensor of the classes of the examples in x.\n",
    "                 and outputs a denoised version of input x.\n",
    "          x_shape: The shape of the generated data. For example, to generate batch_size images of shape (1, H, W),\n",
    "                   x_shape should be (batch_size, 1, H, W).\n",
    "          labels of shape (batch_size,): LongTensor of the classes of generated samples. None for no conditioning\n",
    "                   on classes.\n",
    "        \n",
    "        Note: Create new tensors on the same device where the model is.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0775f8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5ae7e2fd4ce748dc447254ab4500b0ab",
     "grade": false,
     "grade_id": "cell-7b30d34e460fa654",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "diffusion = Diffusion(1000)\n",
    "assert diffusion.betas[0] == 1e-4, \"The lowest temperature should be 1e-4\"\n",
    "assert diffusion.betas[-1] == 0.02, \"The highest temperature should be 0.02\"\n",
    "assert len(diffusion.betas) == 1000, \"The number of steps should be 1000\"\n",
    "\n",
    "def test_diffusion_forward_shapes():\n",
    "    diffusion = Diffusion(1000)\n",
    "    batch_size = 2\n",
    "    x = torch.randn(batch_size, 1, 32, 32)\n",
    "    t = torch.LongTensor([500, 900])\n",
    "    \n",
    "    out = diffusion.forward(x, t)\n",
    "    assert out.shape == x.shape, f\"Bad out.shape: {out.shape}\"\n",
    "\n",
    "    noise = torch.randn_like(x)\n",
    "    out = diffusion.forward(x, t, noise)\n",
    "    assert out.shape == x.shape, f\"Bad out.shape: {out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_diffusion_forward_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052ccbf9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8fd0ae0c6ed8aafebe4724c10c920871",
     "grade": true,
     "grade_id": "cell-5677c1c5306e5d59",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_diffusion_forward():\n",
    "    diffusion = Diffusion(1000)\n",
    "    batch_size = 2\n",
    "    x = 2 * torch.ones(batch_size, 1, 32, 32)\n",
    "    t = torch.LongTensor([500, 900])\n",
    "    noise = torch.ones_like(x)\n",
    "    out = diffusion.forward(x, t, noise)\n",
    "    expected = torch.empty_like(x)\n",
    "    expected[0].fill_(1.51815533)\n",
    "    expected[1].fill_(1.03274309)\n",
    "\n",
    "    print('out:\\n', out)\n",
    "    print('expected correct:\\n', expected)\n",
    "    assert torch.allclose(expected, out), \"out does not match the expected value.\"\n",
    "    print('Success')\n",
    "\n",
    "out = test_diffusion_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5434aa6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "53070ecad791cacf9d17b5aec91e6b4d",
     "grade": false,
     "grade_id": "cell-2d0f0f71bb7383eb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class DummyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x, t, labels=None):\n",
    "        return x\n",
    "\n",
    "def test_diffusion_sample_shapes():\n",
    "    diffusion = Diffusion(1000)\n",
    "    batch_size = 2\n",
    "    x_shape = (batch_size, 1, 32, 32)\n",
    "    model = DummyModel()\n",
    "    \n",
    "    out = diffusion.sample(model, x_shape, labels=None)\n",
    "    assert out.shape == x_shape, f\"Bad out.shape: {out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_diffusion_sample_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07f001",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "84347e1df62ae250935ea8aea0d6898c",
     "grade": true,
     "grade_id": "cell-3b891e5b34a2569e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import unittest.mock\n",
    "\n",
    "def my_randn_like(x):\n",
    "    return torch.ones_like(x)\n",
    "\n",
    "def my_randn(*args, **kwargs):\n",
    "    return torch.ones(*args, **kwargs)\n",
    "\n",
    "def my_normal(mean, std, **kwargs):\n",
    "    return mean + std * torch.ones_like(std)\n",
    "\n",
    "@unittest.mock.patch('torch.randn_like', my_randn_like)\n",
    "@unittest.mock.patch('torch.randn', my_randn)\n",
    "@unittest.mock.patch('torch.normal', my_normal)\n",
    "def test_diffusion_sample():\n",
    "    diffusion = Diffusion(10)\n",
    "    model = DummyModel()\n",
    "    batch_size = 2\n",
    "    x_shape = (batch_size, 1, 32, 32)\n",
    "\n",
    "    out = diffusion.sample(model, x_shape, labels=None)\n",
    "    expected = torch.empty(x_shape).fill_(1.3058254)\n",
    "    print('out:\\n', out)\n",
    "    print('expected correct:\\n', expected)\n",
    "    assert torch.allclose(expected, out), \"out does not match the expected value.\"\n",
    "    print('Success')\n",
    "\n",
    "test_diffusion_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b2b3d0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "524a927d0ff890b27e695d8747d4e239",
     "grade": false,
     "grade_id": "cell-2cb1575cb14a78c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can visualize the forward process in the cell below. Note that since `Diffusion.forward()` samples independent noise instances for different time steps $t$, the illustration below does **not** correspond to steps of the same diffusion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffusion = Diffusion(1000)\n",
    "t = torch.arange(0, diffusion.num_timesteps, 10)\n",
    "x, _ = random.choice(trainset)\n",
    "x = x[None, ...].tile(len(t), 1, 1, 1)  # (t_steps, c, h, w)\n",
    "\n",
    "x_perturbed = diffusion.forward(x, t)\n",
    "tools.show_images(x_perturbed, ncol=10, cmap='binary', clim=[-2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd74f349",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f9762ed763c70a923063973acd4ff4c3",
     "grade": false,
     "grade_id": "cell-949e2d748ea3455a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Construct the denoising model\n",
    "\n",
    "A denoising model is the model that predicts the noise instance $\\epsilon$\n",
    "$$\n",
    "  \\epsilon = f(\\tilde{x}, t, y)\n",
    "$$\n",
    "that was used to generate the corrupted sample $\\tilde{x}$ with the corruption level defined by time step $t$. For denoising conditioned on label $y$, the model additionally accepts the label information $y$ (optional). \n",
    "\n",
    "The output $\\epsilon$ of the model should have the same dimensionality as the input $\\tilde{x}$. The architecture that is very commonly used for $f$ is a U-net.\n",
    "\n",
    "We are not testing the architecture of the U-net in this notebook but the following architecture worked for us:\n",
    "* The model uses blocks `ResidualBlock`, `Downsample` and `PositionalEmbedding` defined in `blocks.py`.\n",
    "* To enable conditioning on time step $t$, we encode the time step using an MLP that is a sequence of the following layers:\n",
    "  * `PositionalEmbedding` with `base_channels` outputs\n",
    "  * `Linear` layer with `time_emb_dim` outputs\n",
    "  * `SiLU` nonlinearity\n",
    "  * `Linear` layer with `time_emb_dim` outputs\n",
    "  \n",
    "* The encoder is a sequence of the following blocks:\n",
    "  * A convolutional layer with 3x3 kernel, `base_channels` output channels, which keeps the resolution of the input.\n",
    "  * `ResidualBlock` with `base_channels` output channels.\n",
    "  * `Downsample` layer which preserves the number of channels.\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `Downsample` layer which preserves the number of channels.\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `Downsample` layer which preserves the number of channels.\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "\n",
    "* The encoder is followed by a bottleneck layer which is\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  \n",
    "* The decoder is a sequence of the following blocks:\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `Upsample` layer which preserves the number of channels.\n",
    "\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `Upsample` layer which preserves the number of channels.\n",
    "\n",
    "  * `ResidualBlock` with `2*base_channels` output channels.\n",
    "  * `ResidualBlock` with `base_channels` output channels.\n",
    "  * `Upsample` layer which preserves the number of channels.\n",
    "\n",
    "  * `ResidualBlock` with `base_channels` output channels.\n",
    "  * `ResidualBlock` with `base_channels` output channels.\n",
    "  * A convolutional layer with 3x3 kernel, `img_channels` output channels, which keeps the resolution of the input.\n",
    "  \n",
    "**Notes:**\n",
    "\n",
    "* Each residual block receives the time-step embedding produced by the MLP defined above and the label of a sample as extra inputs.\n",
    "  \n",
    "* The inputs of the decoder residual blocks are concatenations of two signals: the output of the previous decoder layer and the skip signal produced by the corresponding layer of the encoder.\n",
    "\n",
    "* There are 8 skip signals in totals: they are the outputs of the first convolutional layer and the encoder blocks of type `ResidualBlock` and `Downsample`.\n",
    "\n",
    "* `Upsample` layers of the decoder do not receive skip signals.\n",
    "\n",
    "* **In this exercise, we do not condition our generative model on the class information (the classes of digits). Therefore, we expect argument `num_classes` to be `None`. If you are interested in playing with a generative model conditioned on the class information, you can write your code to support this scenario. We expect no conditioning on classes in the grading tests.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86077142",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1b4a6dc162101998f9818c146ff2d3a1",
     "grade": false,
     "grade_id": "cell-7b96b0da7ae734ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from blocks import ResidualBlock, Downsample, Upsample, PositionalEmbedding\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"The denoising model.\n",
    "    \n",
    "    Args:\n",
    "      img_channels (int): Number of image channels.\n",
    "      base_channels (int): Number of base channels.\n",
    "      time_emb_dim (int or None): The size of the embedding vector produced by the MLP which embeds the time input.\n",
    "      num_classes (int or None): Number of classes, None for no conditioning on classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_channels, base_channels, time_emb_dim=None, num_classes=None):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def forward(self, x, time=None, labels=None):\n",
    "        \"\"\"Estimate noise instances used to produced corrupted examples `x` with the corruption level determined\n",
    "        by `time`. `labels` contains the class information of the examples in `x`.\n",
    "\n",
    "        Args:\n",
    "          x of shape (batch_size, n_channels, H, W): Corrupted examples.\n",
    "          time of shape (batch_size,): LongTensor of time steps which determine the corruption level for\n",
    "                                       the examples in x.\n",
    "          labels of shape (batch_size,): LongTensor of the classes of the examples in x.\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (batch_size, n_channels, H, W)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd88e2e7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68859a5ce44301d755cea4941af2adf9",
     "grade": false,
     "grade_id": "cell-2c65621a090d29df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_UNet_shapes():\n",
    "    unet = UNet(\n",
    "        img_channels=1,\n",
    "        base_channels=128,\n",
    "        time_emb_dim=32,\n",
    "        num_classes=None,\n",
    "    )\n",
    "\n",
    "    batch_size = 3\n",
    "    x = torch.randn(batch_size, 1, 32, 32)\n",
    "    t = torch.LongTensor([0, 1, 2])\n",
    "    labels = None\n",
    "    out = unet(x, t, labels)\n",
    "    assert out.shape == x.shape, f\"Bad out.shape: {out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_UNet_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3213e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4be04796ab3311be1813988090bfa8e7",
     "grade": false,
     "grade_id": "cell-e58c21f485ea4af1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Train the model\n",
    "\n",
    "Implement the training loop in the cell below.\n",
    "\n",
    "The training procedure consists of the following steps for each mini-batch:\n",
    "* Sample uniformly time steps from 0 to `Diffusion.num_timesteps-1` for each training example.\n",
    "* Compute corrupted samples with `Diffusion.forward`.\n",
    "* Estimate the noise used to generate the corrupted samples with the U-net model.\n",
    "* The loss is the MSE loss between the estimated noise and the ground-truth noise.\n",
    "\n",
    "The implementation should follow Algorithm 1 of the paper:\n",
    "<img src=\"alg_training.png\" width=350>\n",
    "\n",
    "\n",
    "The recommended hyperparameters:\n",
    "* Adam optimizer with learning rate 0.001\n",
    "* Number of epochs: 20. If you train longer, the quality of the generated samples should increase further.\n",
    "\n",
    "Hints:\n",
    "- The loss at convergence should reach 0.017 after about 11 epochs. We check that the loss is below 0.02 in the grading tests.\n",
    "- You can track the training progress by plotting 120 generated samples and computing the FD score using the code below\n",
    "```python\n",
    "fdscore = fd.FDScore.pretrained(imsize=32)\n",
    "fdscore.to(device)\n",
    "...\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    x_shape = (120, 1, 32, 32)\n",
    "    samples = diffusion.sample(model, x_shape)\n",
    "    score = fdscore.calculate(samples)\n",
    "\n",
    "    samples = ((samples + 1) / 2).clip(0, 1)\n",
    "    tools.show_images(samples, cmap='binary', ncol=10)\n",
    "\n",
    "    print(f'FD score: {score:.5f}')\n",
    "```\n",
    "- The FD score should be below 2 at convergence. We check that is below 3.5 in the grading tests.\n",
    "- **Do not forget to set the model into the training mode by `net.train()` before training.**\n",
    "- The generated samples are expected to look similar to this:\n",
    "<img src=\"diffusion_samples.png\" width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d61342",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d617c06d096cff1a4ee60d51c1c1594d",
     "grade": false,
     "grade_id": "cell-2ce48e9667bfa679",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a model\n",
    "diffusion = Diffusion(1000)\n",
    "model = UNet(\n",
    "    img_channels=1,\n",
    "    base_channels=32,\n",
    "    time_emb_dim=32,\n",
    "    num_classes=None,\n",
    ")\n",
    "diffusion.to(device);\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640564aa",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "926bf9ae7aceb0fd8dc52d90c8f3f260",
     "grade": false,
     "grade_id": "cell-5b01edf28b1f0002",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98c514b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "# Set confirm=False if you do not want to be asked for confirmation before saving.\n",
    "if not skip_training:\n",
    "    tools.save_model(diffusion, '1_diffusion.pth', confirm=True)\n",
    "    tools.save_model(model, '1_unet.pth', confirm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b186fc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d2190a46a9488d9a99f7f8437be786a",
     "grade": false,
     "grade_id": "cell-ea31927b1902eb46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    diffusion = Diffusion(1000)\n",
    "    model = UNet(\n",
    "        img_channels=1,\n",
    "        base_channels=32,\n",
    "        time_emb_dim=32,\n",
    "        num_classes=None,\n",
    "    )\n",
    "    \n",
    "    tools.load_model(diffusion, '1_diffusion.pth', device)\n",
    "    tools.load_model(model, '1_unet.pth', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136da2e1",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4f99f3d1538640b4023a8ef1111a2290",
     "grade": false,
     "grade_id": "cell-f2ac7d8e180308fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2214a7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1681b0d8e0d61bd8022af927b6b75fef",
     "grade": true,
     "grade_id": "cell-f1f1660f4e07409c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Save generated samples (the pth-files will be submitted automatically together with your notebook)\n",
    "if not skip_training:\n",
    "    with torch.no_grad():\n",
    "        x_shape = (120, 1, 32, 32)\n",
    "        samples = diffusion.sample(model, x_shape)\n",
    "        torch.save(samples, '1_samples.pth')\n",
    "else:\n",
    "    samples = torch.load('1_samples.pth', map_location=lambda storage, loc: storage)\n",
    "\n",
    "fdscore = fd.FDScore.pretrained(imsize=32)\n",
    "fdscore.to(device)\n",
    "score = fdscore.calculate(samples)\n",
    "print('FD score:', score)\n",
    "assert score < 3.5, 'The FD score should be below 3.5'\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea4ac51",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "403f94a2ff50bd9b47cc755506f739e3",
     "grade": false,
     "grade_id": "cell-72871ea5ca45dd8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "samples01 = ((samples + 1) / 2).clip(0, 1)\n",
    "tools.show_images(samples01, cmap='binary', ncol=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f75cb4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4503a3d4d48dad538f1582b9a7c2707e",
     "grade": true,
     "grade_id": "cell-ba1728626cc1c211",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests the training loss of the trained denoising model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fdbc69",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c7bdd75c4de70853688d5dbf37cf68c",
     "grade": false,
     "grade_id": "cell-77a89d4ae55de964",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## In-painting: Conditional generation given known parts of a generated image\n",
    "\n",
    "One of the benefits of diffusion-based generative model is the possibility to use a trained model for *conditional* generation of some parts (of an image) given known values of other parts. For example, given the top part of an image (like in the images shown below)\n",
    "<img src=\"conditioning.png\" width=400>\n",
    "the model can generate samples which have the given values in the top part:\n",
    "<img src=\"cond_samples.png\" width=400>\n",
    "\n",
    "In the cell below, your need to implement a function that generate samples conditioned on known parts of samples using your trained diffusion model.\n",
    "\n",
    "Hints:\n",
    "* There are different ways of performing this task but the most straightforward implementation contains a single for-loop similar to the standard reverse-diffusion process. The only difference is that the pixels of the known parts should converge to the known values by using an appropriate distribution to draw samples from.\n",
    "\n",
    "* We recommend you to figure out the required math from [the original DDPM paper](https://arxiv.org/pdf/2006.11239.pdf).\n",
    "\n",
    "* **In this exercise, we do not condition our generative model on the class information (the classes of digits). Therefore, we expect argument `labels` to be `None`. If you are interested in playing with a generative model conditioned on the class information, you can write your code to support this scenario. We expect no conditioning on classes in the grading tests.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1cbb9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1e53f8eaaada96723b0ce7b2eb770bcd",
     "grade": false,
     "grade_id": "cell-d287916089898f93",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def inpaint(diffusion, model, images, mask_known, labels=None):\n",
    "    \"\"\"Generate samples conditioned on known parts of images.\n",
    "    \n",
    "    Args:\n",
    "      diffusion (Diffusion): The descriptor of a diffusion model.\n",
    "      model: A denoising model: model(x, t, labels) outputs a denoised version of input x.\n",
    "      images of shape (batch_size, n_channels, H, W): Conditioning images.\n",
    "      mask_known of shape (batch_size, 1, H, W): BoolTensor which specifies known pixels in images (marked as True).\n",
    "      labels of shape (batch_size,): Classes of images, None for no conditioning on classes.\n",
    "    \n",
    "    Returns:\n",
    "      x of shape (batch_size, n_channels, H, W): Generated samples (one sample per input image).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c722e6d9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3681e9f49b57dfec5ffaf555493aeea0",
     "grade": false,
     "grade_id": "cell-ae88371d04a5f4b8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This script uses your function to perform conditional generation\n",
    "if not skip_training:\n",
    "    with torch.no_grad():\n",
    "        #(images, labels) = next(iter(trainloader))\n",
    "        image, label = trainset[4]  # Select one image from the dataset\n",
    "        images = image[None, 0].tile(120, 1, 1, 1)  # Copy the image to generate multiple samples\n",
    "        images = images.to(device)\n",
    "        labels = None\n",
    "        (batch_size, _, H, W) = images.shape\n",
    "\n",
    "        # mask out the bottom part of every image\n",
    "        mask_known = torch.zeros(batch_size, 1, H, W, dtype=torch.bool, device=device)\n",
    "        mask_known[:, :, :H//2, :] = 1\n",
    "        images_known = images * mask_known\n",
    "\n",
    "        samples01 = ((images_known + 1) / 2).clip(0, 1)\n",
    "        print('Conditioning:')\n",
    "        tools.show_images(samples01[:120], cmap='binary', ncol=12)\n",
    "\n",
    "        samples = inpaint(diffusion, model, images_known, mask_known, labels=None)\n",
    "        samples01 = ((samples + 1) / 2).clip(0, 1)\n",
    "        tools.show_images(samples01[:120], cmap='binary', ncol=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3fbee8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e91d28a9792c3ee473203f4fe4a9719b",
     "grade": true,
     "grade_id": "cell-52c9f4f6db25c28f",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def test_fid_score_inpaint(diffusion, model):\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=False)\n",
    "    \n",
    "    (images, labels) = next(iter(trainloader))\n",
    "    images = images.to(device)\n",
    "    labels = None\n",
    "    (batch_size, _, H, W) = images.shape\n",
    "\n",
    "    # mask out the bottom part of every image\n",
    "    mask_known = torch.zeros(batch_size, 1, H, W, dtype=torch.bool, device=device)\n",
    "    mask_known[:, :, :H//2, :] = 1\n",
    "    images_known = images * mask_known\n",
    "\n",
    "    if not skip_training:\n",
    "        model.eval()\n",
    "        samples = inpaint(diffusion, model, images_known, mask_known, labels=None)\n",
    "        torch.save(samples, '1_cond_samples.pth')\n",
    "\n",
    "    else:\n",
    "        samples = torch.load('1_cond_samples.pth', map_location=lambda storage, loc: storage)\n",
    "\n",
    "    # Check conditioning\n",
    "    mse = (samples - images)[mask_known].square().mean().item()\n",
    "    print('MSE:', mse)\n",
    "    assert mse < 1e-5, 'The known pixels should not change.'\n",
    "    \n",
    "    fdscore = fd.FDScore.pretrained(imsize=32)\n",
    "    fdscore.to(device)\n",
    "    score = fdscore.calculate(samples)\n",
    "    print('FD score:', score)\n",
    "    assert score < 3.5, 'The FD score should be below 3.5.'\n",
    "    print('Success')\n",
    "\n",
    "test_fid_score_inpaint(diffusion, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815d9e65",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e8a8301525447b2b71e601aafb707020",
     "grade": false,
     "grade_id": "cell-07cb009a4da0e0c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion</b>\n",
    "</div>\n",
    "\n",
    "In this exercise, we trained a diffusion-based generative model and learned how to use the trained model for image in-painting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
