{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7c47e5076bf903b3f15a435f9e309707",
     "grade": false,
     "grade_id": "cell-440df6cfa709812f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Deadline:</b> March 16, 2022 (Wednesday) 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 2. Convolutional networks. VGG-style network.\n",
    "\n",
    "In the second part you need to train a convolutional neural network with an architecture inspired by a VGG-network [(Simonyan \\& Zisserman, 2015)](https://arxiv.org/abs/1409.1556)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65e2970339980ef7d85c3754662c4ee8",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tools\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48d33ffe246f5459117f53cac15b370d",
     "grade": false,
     "grade_id": "cell-fe95dcf02c6b9c5e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f2b11aa8f0d0377563333bd78493751",
     "grade": false,
     "grade_id": "cell-e5b565cc4aae8e7f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## FashionMNIST dataset\n",
    "\n",
    "Let us use the FashionMNIST dataset. It consists of 60,000 training images of 10 classes: 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9fb758b86d03e9884930cd772a48671",
     "grade": false,
     "grade_id": "cell-8b0fded08998282c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6cde19253d8a93916505d95820bd979",
     "grade": false,
     "grade_id": "cell-4ab9d042e4edcd54",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# VGG-style network\n",
    "\n",
    "Let us now define a convolution neural network with an architecture inspired by the [VGG-net](https://arxiv.org/abs/1409.1556).\n",
    "\n",
    "The architecture:\n",
    "- A block of three convolutional layers with:\n",
    "    - 3x3 kernel\n",
    "    - 20 output channels\n",
    "    - one pixel zero-pading on both sides\n",
    "    - 2d batch normalization after each convolutional layer\n",
    "    - ReLU nonlinearity after each 2d batch normalization layer\n",
    "- Max pooling layer with 2x2 kernel and stride 2.\n",
    "- A block of three convolutional layers with:\n",
    "    - 3x3 kernel\n",
    "    - 40 output channels\n",
    "    - one pixel zero-pading on both sides\n",
    "    - 2d batch normalization after each convolutional layer\n",
    "    - ReLU nonlinearity after each 2d batch normalization layer\n",
    "- Max pooling layer with 2x2 kernel and stride 2.\n",
    "- One convolutional layer with:\n",
    "    - 3x3 kernel\n",
    "    - 60 output channels\n",
    "    - *no padding*\n",
    "    - 2d batch normalization after the convolutional layer\n",
    "    - ReLU nonlinearity after the 2d batch normalization layer\n",
    "- One convolutional layer with:\n",
    "    - 1x1 kernel\n",
    "    - 40 output channels\n",
    "    - *no padding*\n",
    "    - 2d batch normalization after the convolutional layer\n",
    "    - ReLU nonlinearity after the 2d batch normalization layer\n",
    "- One convolutional layer with:\n",
    "    - 1x1 kernel\n",
    "    - 20 output channels\n",
    "    - *no padding*\n",
    "    - 2d batch normalization after the convolutional layer\n",
    "    - ReLU nonlinearity after the 2d batch normalization layer\n",
    "- Global average pooling (compute the average value of each channel across all the input locations):\n",
    "    - 5x5 kernel (the input of the layer should be 5x5)\n",
    "- A fully-connected layer with 10 outputs (no nonlinearity)\n",
    "\n",
    "Notes:\n",
    "* Batch normalization is expected to be right after a convolutional layer, before nonlinearity.\n",
    "* We recommend that you check the number of modules with trainable parameters in your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28866c07a4d64281f3b81ca0e16b4954",
     "grade": false,
     "grade_id": "cell-958d9ce586a51bd3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class VGGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGNet, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        # Block 1(3 CNN layers): 3x3 kernel, 20 output channels, one pixel zero-pading on both sides,2d batch normalization\n",
    "        self.b1_cl1 = nn.Conv2d(1, 20, (3, 3), padding = 1)\n",
    "        self.b1_bn1 = nn.BatchNorm2d(20)\n",
    "        \n",
    "        self.b1_cl2 = nn.Conv2d(20, 20, (3, 3), padding = 1)\n",
    "        self.b1_bn2 = nn.BatchNorm2d(20)\n",
    "        \n",
    "        self.b1_cl3 = nn.Conv2d(20, 20, (3, 3), padding = 1)\n",
    "        self.b1_bn3 = nn.BatchNorm2d(20)\n",
    "        \n",
    "        # Max pooling layer with 2x2 kernel and stride 2\n",
    "        self.mp1 = nn.MaxPool2d((2, 2), stride=2)\n",
    "        \n",
    "        # Block 2: 3x3 kernel, 40 output channels, one pixel zero-pading on both sides,2d batch normalization\n",
    "        self.b2_cl1 = nn.Conv2d(20, 40, (3, 3), padding = 1)\n",
    "        self.b2_bn1 = nn.BatchNorm2d(40)\n",
    "        \n",
    "        self.b2_cl2 = nn.Conv2d(40, 40, (3, 3), padding = 1)\n",
    "        self.b2_bn2 = nn.BatchNorm2d(40)\n",
    "        \n",
    "        self.b2_cl3 = nn.Conv2d(40, 40, (3, 3), padding = 1)\n",
    "        self.b2_bn3 = nn.BatchNorm2d(40)\n",
    "        \n",
    "        # Max pooling layer with 2x2 kernel and stride 2\n",
    "        self.mp2 = nn.MaxPool2d((2, 2), stride=2)\n",
    "        \n",
    "        # Block 3: 3x3 kernel, 60 output channels, no padding,2d batch normalization\n",
    "        self.b3_cl1 = nn.Conv2d(40, 60, (3, 3))\n",
    "        self.b3_bn1 = nn.BatchNorm2d(60)\n",
    "        \n",
    "        self.b3_cl2 = nn.Conv2d(60, 40, (1, 1))\n",
    "        self.b3_bn2 = nn.BatchNorm2d(40)\n",
    "        \n",
    "        self.b3_cl3 = nn.Conv2d(40, 20, (1, 1))\n",
    "        self.b3_bn3 = nn.BatchNorm2d(20)\n",
    "        \n",
    "        # Global average pooling: 5x5 kernel\n",
    "        self.gap = nn.AvgPool2d((5, 5))\n",
    "        # A fully-connected layer with 10 outputs\n",
    "        self.fc = nn.Linear(20, 10)\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Input images.\n",
    "          verbose: True if you want to print the shapes of the intermediate variables.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (batch_size, 10): Outputs of the network.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        y = F.relu(self.b1_bn1(self.b1_cl1(x)))\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "        y = F.relu(self.b1_bn2(self.b1_cl2(y)))\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "        y = F.relu(self.b1_bn3(self.b1_cl3(y)))\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "            \n",
    "        y = self.mp1(y)\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "        \n",
    "        y = F.relu(self.b2_bn1(self.b2_cl1(y)))\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "        y = F.relu(self.b2_bn2(self.b2_cl2(y)))\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "        y = F.relu(self.b2_bn3(self.b2_cl3(y)))\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "            \n",
    "        y = self.mp2(y)\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "        \n",
    "        y = F.relu(self.b3_bn1(self.b3_cl1(y)))\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "        y = F.relu(self.b3_bn2(self.b3_cl2(y)))\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "        y = F.relu(self.b3_bn3(self.b3_cl3(y)))\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "        \n",
    "        y = self.gap(y)\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "            \n",
    "        # Get the number of flat features\n",
    "        feature = 1\n",
    "        for size in y.size()[1:]:\n",
    "            feature *= size\n",
    "        \n",
    "        y = y.view(-1, feature)\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "        \n",
    "        y = self.fc(y)\n",
    "        if verbose: \n",
    "            print(y.shape)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "44870ad6dd02b719505a9dfd353943ac",
     "grade": false,
     "grade_id": "cell-e9e9a9dcda247c96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input tensor: torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 20, 28, 28])\n",
      "torch.Size([32, 20, 28, 28])\n",
      "torch.Size([32, 20, 28, 28])\n",
      "torch.Size([32, 20, 14, 14])\n",
      "torch.Size([32, 40, 14, 14])\n",
      "torch.Size([32, 40, 14, 14])\n",
      "torch.Size([32, 40, 14, 14])\n",
      "torch.Size([32, 40, 7, 7])\n",
      "torch.Size([32, 60, 5, 5])\n",
      "torch.Size([32, 40, 5, 5])\n",
      "torch.Size([32, 20, 5, 5])\n",
      "torch.Size([32, 20, 1, 1])\n",
      "torch.Size([32, 20])\n",
      "torch.Size([32, 10])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_VGGNet_shapes():\n",
    "    net = VGGNet()\n",
    "    net.to(device)\n",
    "\n",
    "    # Feed a batch of images from the training data to test the network\n",
    "    with torch.no_grad():\n",
    "        images, labels = iter(trainloader).next()\n",
    "        images = images.to(device)\n",
    "        print('Shape of the input tensor:', images.shape)\n",
    "\n",
    "        y = net(images, verbose=True)\n",
    "        assert y.shape == torch.Size([trainloader.batch_size, 10]), f\"Bad y.shape: {y.shape}\"\n",
    "\n",
    "    print('Success')\n",
    "\n",
    "test_VGGNet_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0572dacc9b9279189742374851ca22e",
     "grade": true,
     "grade_id": "test_VGGNet",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c87ccb8eb839f919438ec33b6d8f5e3b",
     "grade": false,
     "grade_id": "cell-6c5c6ddc6d0312e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f83e3828402226248c665aa6b1f49a8",
     "grade": false,
     "grade_id": "cell-9e3a0480727aec61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e950179b6eff433fd41deb20bf35da9c",
     "grade": false,
     "grade_id": "cell-d168751b85ea2490",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Your task is to implement the training loop. The recommended hyperparameters:\n",
    "* Adam optimizer with learning rate 0.01.\n",
    "* Cross-entropy loss. Note that we did not use softmax nonlinearity in the final layer of our network. Therefore, we need to use a loss function with log_softmax implemented, such as [`nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss).\n",
    "* Number of epochs: 10\n",
    "\n",
    "We recommend you to use function `compute_accuracy()` defined above to track the accaracy during training. The test accuracy should be above 0.89.\n",
    "\n",
    "**Note: function `compute_accuracy()` sets the network into the evaluation mode which changes the way the batch statistics are computed in batch normalization. You need to set the network into the training mode (by calling `net.train()`) when you want to perform training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db3a9615921b7a80d333475aa66ae69b",
     "grade": false,
     "grade_id": "cell-d5bf19391acb3661",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "net = VGGNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6270848f5387bf01aba9bb5f50303a78",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement the training loop in this cell\n",
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    net.zero_grad()\n",
    "    lossFunc = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "    \n",
    "    for _ in range(10):\n",
    "        net.train()\n",
    "        for images, labels in trainloader:   \n",
    "            optimizer.zero_grad()\n",
    "            y = net(images)\n",
    "            loss = lossFunc(y, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        accuracy = compute_accuracy(net,testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "# Set confirm=False if you do not want to be asked for confirmation before saving.\n",
    "if not skip_training:\n",
    "    tools.save_model(net, '2_vgg_net.pth', confirm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fb57a1a2e5a8cd05e115cf98ed7635a",
     "grade": false,
     "grade_id": "cell-28a73d35f35e73c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from 2_vgg_net.pth.\n"
     ]
    }
   ],
   "source": [
    "if skip_training:\n",
    "    net = VGGNet()\n",
    "    tools.load_model(net, '2_vgg_net.pth', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63bba11d24ab5d7fd716a8930b4f1bc8",
     "grade": true,
     "grade_id": "accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the accuracy on the test set\n",
    "accuracy = compute_accuracy(net, testloader)\n",
    "print(f'Accuracy of the VGG net on the test images: {accuracy: .3f}')\n",
    "assert accuracy > 0.89, 'Poor accuracy'\n",
    "print('Success')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
