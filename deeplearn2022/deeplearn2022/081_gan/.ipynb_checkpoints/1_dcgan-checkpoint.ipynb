{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "afdac0e489ea9a36f68ff82ebeefaff1",
     "grade": false,
     "grade_id": "cell-3941e0c28ecf711b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Deadline:</b> May 4, 2022 (Wednesday) 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 1. Generative adversarial networks (GANs). DCGAN: Deep convolutional GAN\n",
    "\n",
    "The goal of this exercise is to get familiar with generative adversarial networks and specifically DCGAN. The model was proposed by [Radford et al., 2015](https://arxiv.org/pdf/1511.06434.pdf).\n",
    "\n",
    "DCGAN is probably the simplest GAN model which is relatively easy to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3eb0d8430b430162c5ea92d25e5a5061",
     "grade": true,
     "grade_id": "cell-bd68b7386e29d846",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fontconfig error: Cannot load default config file: No such file: (null)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "import tools\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cd275621253cd028c5065035e3390f93",
     "grade": false,
     "grade_id": "cell-2212a6a282e966a9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "04ce3d7c3c2e4c327a34405291398340",
     "grade": false,
     "grade_id": "cell-140f604a5cb368f8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "We will use MNIST data in this exercise. **Note that we re-scale images so that the pixel intensities are in the range [-1, 1].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a57252aa059b4324485613a29450837d",
     "grade": false,
     "grade_id": "cell-55039c5db5aa5d3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "batch_size = 100\n",
    "dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ceff023afd66794411ec51227791aa54",
     "grade": false,
     "grade_id": "cell-797591c879634741",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Generative adversarial networks\n",
    "\n",
    "Our task is to train a generative model of the data, that is a model from which we can draw samples that will have a distribution similar to the distribution of the training data (MNIST digits in our case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9017381ae18064c6b3dc34b1e836e7c3",
     "grade": false,
     "grade_id": "cell-9356f4dc68bfdc4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Generator\n",
    "\n",
    "The generative model that we are going to train is:\n",
    "\\begin{align}\n",
    "z &\\sim N(0, I)\n",
    "\\\\\n",
    "x &= g(z)\n",
    "\\end{align}\n",
    "that is the data is generated by applying a nonlinear transformation to samples drawn from the standard normal distribution.\n",
    "\n",
    "We are going to model $g$ with a deep neural network created below. In DCGAN, the generator is made of only transposed convolutional layers `ConvTranspose2d`.\n",
    "The proposed architecture for the generator:\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `4*ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and ReLU\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `2*ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and ReLU\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `ngf` output channels, no bias,\n",
    "   followed by `BatchNorm2d` and ReLU\n",
    "* `ConvTranspose2d` layer with `kernel_size=4`, `stride=2`, `nc` output channels, no bias,\n",
    "   followed by `tanh`.\n",
    "\n",
    "The `tanh` nonlinearity guarantees that the output is between -1 and 1 which holds for our scaling of the training data.\n",
    "\n",
    "* **The exact architecture is not tested in this assignment.**\n",
    "* **The description above is not full. To get the correct output shape, you need to set correctly other parameters of the `ConvTranspose2d` layers. Note that training may fail for some padding schemes. If training fails but everything else looks correct, try changing the padding scheme.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a26a1e9624ea328d6bdc50a403e96da4",
     "grade": false,
     "grade_id": "Generator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz=10, ngf=64, nc=1):\n",
    "        \"\"\"GAN generator.\n",
    "        \n",
    "        Args:\n",
    "          nz:  Number of elements in the latent code.\n",
    "          ngf: Base size (number of channels) of the generator layers.\n",
    "          nc:  Number of channels in the generated images.\n",
    "        \"\"\"\n",
    "        super(Generator, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        # ConvTranspose2d layer with kernel_size=4, stride=2, 4*ngf output channels, no bias, followed by BatchNorm2d and ReLU\n",
    "        self.gen_conv1 = nn.ConvTranspose2d(kernel_size = 4, stride = 2,in_channels = nz, out_channels = 4*ngf, bias = False, padding = 0)\n",
    "        self.norm1 = nn.BatchNorm2d(num_features = 4*ngf )\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        # ConvTranspose2d layer with kernel_size=4, stride=2, 2*ngf output channels, no bias, followed by BatchNorm2d and ReLU\n",
    "        self.gen_conv2 = nn.ConvTranspose2d(kernel_size = 4, stride = 2,in_channels = 4*ngf, out_channels = 2*ngf, bias = False, padding = 1)\n",
    "        self.norm2 = nn.BatchNorm2d(num_features = 2*ngf )\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # ConvTranspose2d layer with kernel_size=4, stride=2, ngf output channels, no bias, followed by BatchNorm2d and ReLU\n",
    "        self.gen_conv3 = nn.ConvTranspose2d(kernel_size = 4, stride = 2, in_channels = 2*ngf, out_channels = ngf, bias = False, padding = 2)\n",
    "        self.norm3 = nn.BatchNorm2d(num_features = ngf )\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # ConvTranspose2d layer with kernel_size=4, stride=2, nc output channels, no bias, followed by tanh\n",
    "        self.gen_conv4 = nn.ConvTranspose2d(kernel_size = 4, stride = 2, in_channels = ngf, out_channels = nc, bias = False, padding = 1)\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "    def forward(self, z, verbose=False):\n",
    "        \"\"\"Generate images by transforming the given noise tensor.\n",
    "        \n",
    "        Args:\n",
    "          z of shape (batch_size, nz, 1, 1): Tensor of noise samples. We use the last two singleton dimensions\n",
    "                          so that we can feed z to the generator without reshaping.\n",
    "          verbose (bool): Whether to print intermediate shapes (True) or not (False).\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (batch_size, nc, 28, 28): Generated images.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        if verbose: print(z.size())\n",
    "            \n",
    "        out = self.relu1(self.norm1(self.gen_conv1(z)))\n",
    "        if verbose: print(out.size())\n",
    "            \n",
    "        out = self.relu2(self.norm2(self.gen_conv2(out)))\n",
    "        if verbose: print(out.size())\n",
    "            \n",
    "        out = self.relu3(self.norm3(self.gen_conv3(out)))\n",
    "        if verbose: print(out.size())\n",
    "        \n",
    "        out = self.tanh(self.gen_conv4(out))\n",
    "        if verbose: print(out.size())\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b80ee06fd8f120e253712503ca8dcbea",
     "grade": false,
     "grade_id": "cell-65fe5c0af77b5d74",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 1, 1])\n",
      "torch.Size([32, 256, 4, 4])\n",
      "torch.Size([32, 128, 8, 8])\n",
      "torch.Size([32, 64, 14, 14])\n",
      "torch.Size([32, 1, 28, 28])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_Generator_shapes():\n",
    "    nz = 10\n",
    "    netG = Generator(nz, ngf=64, nc=1)\n",
    "\n",
    "    batch_size = 32\n",
    "    noise = torch.randn(batch_size, nz, 1, 1)\n",
    "    out = netG(noise, verbose=True)\n",
    "\n",
    "    assert out.shape == torch.Size([batch_size, 1, 28, 28]), f\"Bad shape of out: out.shape={out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Generator_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab5a58be5bcef66ea9316f080270a0e9",
     "grade": false,
     "grade_id": "cell-0151d274de94f50d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loss for training the generator\n",
    "\n",
    "The generative model will be guided by a discriminator whose task is to separate (classify) data into two classes:\n",
    "* true data (samples from the training set)\n",
    "* generated data (samples generated by the generator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7bb6fa5353ab5f0262705a5fea9b38e2",
     "grade": false,
     "grade_id": "cell-3f77648eb2fe0ea1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1.\n",
    "fake_label = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c815e41e4de9f630bc1b63ee3089bd4c",
     "grade": false,
     "grade_id": "cell-7f59b33f30149a9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The task of the generator is to confuse the discriminator as much as possible, which is the case when the distribution produced by the generator perfectly replicates the data distribution.\n",
    "\n",
    "In the cell below, you need to implement the loss function which is used to train the generator. The loss should be the `binary_cross_entropy` loss computed with `real_label` as targets for the generated samples.\n",
    "\n",
    "**IMPORTANT: Please use the `mean` reduction when computing the loss!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ec1dbae1eb2d04179fcdc7ffe64b0bc",
     "grade": false,
     "grade_id": "generator_loss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generator_loss(netD, fake_images):\n",
    "    \"\"\"Loss computed to train the GAN generator.\n",
    "\n",
    "    Args:\n",
    "      netD: The discriminator whose forward function takes inputs of shape (batch_size, nc, 28, 28)\n",
    "         and produces outputs of shape (batch_size, 1).\n",
    "      fake_images of shape (batch_size, nc, 28, 28): Fake images produces by the generator.\n",
    "\n",
    "    Returns:\n",
    "      loss: The mean of the binary cross-entropy losses computed for all the samples in the batch.\n",
    "\n",
    "    Notes:\n",
    "    - Make sure that you process on the device given by `fake_images.device`.\n",
    "    - Use values of global variables `real_label`, `fake_label` to produce the right targets.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    size = fake_images.shape[0]\n",
    "    target = torch.ones(size)*real_label\n",
    "    \n",
    "    out = netD.forward(fake_images)\n",
    "    \n",
    "    loss = F.binary_cross_entropy(out, target)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a59db8f81b28a77cd02b5c3d5eb926cf",
     "grade": true,
     "grade_id": "test_Generator_loss",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests generator_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2554c161811028fc12e15c5b9738c171",
     "grade": false,
     "grade_id": "cell-63faa114782d7e87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Discriminator\n",
    "\n",
    "In DCGAN, the discriminator is a stack of only convolutional layers.\n",
    "\n",
    "The proposed architecture for the discriminator:\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `ndf` output channels, no bias,\n",
    "   followed by BatchNorm2d and LeakyReLU(0.2)\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `2*ndf` output channels, no bias,\n",
    "   followed by BatchNorm2d and LeakyReLU(0.2)\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, `4*ndf` output channels, no bias,\n",
    "   followed by BatchNorm2d and LeakyReLU(0.2)\n",
    "* `Conv2d` layer with `kernel_size=4`, `stride=2`, 1 output channel, no bias,\n",
    "   followed by `sigmoid`.\n",
    "\n",
    "Notes:\n",
    "* **The exact architecture is not tested in this assignment.**\n",
    "* **The description is not full, please fill the missing pieces by yourself.**\n",
    "* In this exercise, the discriminator works well without batch normalization layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f7aac6360862eb5f3d3fcdae2277ae6",
     "grade": false,
     "grade_id": "Discriminator",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, nc=1, ndf=64):\n",
    "        \"\"\"GAN discriminator.\n",
    "        \n",
    "        Args:\n",
    "          nc:  Number of channels in images.\n",
    "          ndf: Base size (number of channels) of the discriminator layers.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Conv2d layer with kernel_size=4, stride=2, ndf output channels, no bias, followed by BatchNorm2d and LeakyReLU(0.2)\n",
    "        self.dis_conv1 = nn.Conv2d(in_channels=nc, out_channels=ndf, kernel_size=4, stride=2, bias=False, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(num_features = ndf )\n",
    "        self.relu1 = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        # Conv2d layer with kernel_size=4, stride=2, ndf output channels, no bias, followed by BatchNorm2d and LeakyReLU(0.2)\n",
    "        self.dis_conv2 = nn.Conv2d(in_channels=ndf, out_channels=2*ndf, kernel_size=4, stride=2, bias=False, padding=2)\n",
    "        self.norm2 = nn.BatchNorm2d(num_features = 2*ndf )\n",
    "        self.relu2 = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        # Conv2d layer with kernel_size=4, stride=2, 4*ndf output channels, no bias, followed by BatchNorm2d and LeakyReLU(0.2)\n",
    "        self.dis_conv3 = nn.Conv2d(in_channels=2*ndf, out_channels=4*ndf, kernel_size=4, stride=2, bias=False, padding=1)\n",
    "        self.norm3 = nn.BatchNorm2d(num_features = 4*ndf )\n",
    "        self.relu3 = nn.LeakyReLU(0.2)\n",
    "        \n",
    "        # Conv2d layer with kernel_size=4, stride=2, 1 output channel, no bias, followed by sigmoid.\n",
    "        self.dis_conv4 = nn.Conv2d(in_channels=4*ndf, out_channels=1, kernel_size=4, stride=2, bias=False, padding=0)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        \"\"\"Classify given images into real/fake.\n",
    "        \n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Images to be classified.\n",
    "        \n",
    "        Returns:\n",
    "          out of shape (batch_size,): Probabilities that images are real. All elements should be between 0 and 1.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        if verbose: print(x.size())\n",
    "        \n",
    "        out = self.relu1(self.norm1(self.dis_conv1(x)))\n",
    "        if verbose: print(out.size())\n",
    "        \n",
    "        out = self.relu2(self.norm2(self.dis_conv2(out)))\n",
    "        if verbose: print(out.size())\n",
    "        \n",
    "        out = self.relu3(self.norm3(self.dis_conv3(out)))\n",
    "        if verbose: print(out.size())\n",
    "            \n",
    "        out = self.sig(self.dis_conv4(out))\n",
    "        if verbose: print(out.size())\n",
    "            \n",
    "        out = np.squeeze(out)\n",
    "        if verbose: print(out.size())\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc353b6ac051abe22c8f022a7860c348",
     "grade": false,
     "grade_id": "cell-cef1ff3c74404557",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_Discriminator_shapes():\n",
    "    batch_size = 32\n",
    "    netD = Discriminator(nc=1, ndf=64)\n",
    "\n",
    "    images = torch.ones(32, 1, 28, 28)\n",
    "    out = netD(images, verbose=True)\n",
    "\n",
    "    assert out.shape == torch.Size([batch_size]), f\"Bad shape of out: out.shape={out.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Discriminator_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6523502226d744a59c86163eee57e75a",
     "grade": false,
     "grade_id": "cell-51681d3003e07996",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Loss for training the discriminator\n",
    "\n",
    "The discriminator is trained to solve a binary classification problem: to separate real data from generated samples. Thus, the output of the discriminator should be a scalar between 0 and 1.\n",
    "\n",
    "You need to implement the loss function used to train the discriminator. The dicriminator uses the `binary_cross_entropy` loss using `real_label` as targets for real samples and `fake_label` as targets for generated samples.\n",
    "\n",
    "**IMPORTANT: Please use the `mean` reduction when computing the loss!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "440db54740e04d60aa69cd1c134691dc",
     "grade": false,
     "grade_id": "discriminator_loss",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(netD, real_images, fake_images):\n",
    "    \"\"\"Loss computed to train the GAN discriminator.\n",
    "\n",
    "    Args:\n",
    "      netD: The discriminator.\n",
    "      real_images of shape (batch_size, nc, 28, 28): Real images.\n",
    "      fake_images of shape (batch_size, nc, 28, 28): Fake images produces by the generator.\n",
    "\n",
    "    Returns:\n",
    "      d_loss_real: The mean of the binary cross-entropy losses computed on the real_images.\n",
    "      D_real: Mean output of the discriminator for real_images. This is useful for tracking convergence.\n",
    "      d_loss_fake: The mean of the binary cross-entropy losses computed on the fake_images.\n",
    "      D_fake: Mean output of the discriminator for fake_images. This is useful for tracking convergence.\n",
    "\n",
    "    Notes:\n",
    "    - Make sure that you process on the device given by `fake_images.device`.\n",
    "    - Use values of global variables `real_label`, `fake_label` to produce the right targets.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd4029769ed532dff0b85dce6a77184c",
     "grade": true,
     "grade_id": "cell-461f1d2ee56f035d",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_discriminator_loss():\n",
    "    netD = Discriminator(nc=1, ndf=64)\n",
    "    real_images = fake_images = torch.ones(32, 1, 28, 28)\n",
    "\n",
    "    d_loss_real, D_real, d_loss_fake, D_fake = discriminator_loss(netD, real_images, fake_images)\n",
    "    assert d_loss_real.shape == torch.Size([]), \"d_loss_real should be a scalar tensor.\"\n",
    "    assert 0 < D_real < 1, \"D_real should be a scalar between 0 and 1.\"\n",
    "    assert d_loss_fake.shape == torch.Size([]), \"d_loss_fake should be a scalar tensor.\"\n",
    "    assert 0 < D_fake < 1, \"D_fake should be a scalar between 0 and 1.\"\n",
    "    print('Success')\n",
    "\n",
    "test_discriminator_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c5d6b90dd61ec79abd9a105af1d4f737",
     "grade": true,
     "grade_id": "test_Discriminator_loss",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell tests discriminator_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2ce91d7e84c593bcd3eb8568b086cea",
     "grade": false,
     "grade_id": "cell-32a46a6724373e1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Evaluation of quality of generated samples\n",
    "\n",
    "We would like to evaluate the quality of the generated samples using some metric. Designing such a metric is not a trivial task. The most popular metric for assessing the quality of generated images is FrÃ©chet Inception Distance (FID) [(Heusel et al., 2017)](https://arxiv.org/abs/1706.08500). The FID score compares the distribution of intermediate activations when real or generated samples are passed through an Inception network. The Inception network is a specific type of a convolutional neural network that is pre-trained on image classification tasks.\n",
    "\n",
    "In this exercise, we do not generate natural images and therefore we do not use the Inception network to compute the activations. Instead, we use a simple convolutional neural network trained to classify MNIST digits. Therefore, we call the metric FD score (dropping the word *Inception*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f93c4e446fa89f08395d80db52bae206",
     "grade": false,
     "grade_id": "cell-7292f1f13a3359dd",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import fd\n",
    "\n",
    "# Load an FD scorer pre-trained on MNIST\n",
    "fdscore = fd.FDScore.pretrained()\n",
    "fdscore.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fbe7284b80697efad494a5b4e711827f",
     "grade": false,
     "grade_id": "cell-1b6b5eca75e178fe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Score on uniform noise in the range [-1, 1]\n",
    "samples = torch.rand(10000, 1, 28, 28).to(device)\n",
    "samples = (samples - 0.5) * 2\n",
    "score = fdscore.calculate(samples)\n",
    "print(f'Score on Gaussian noise: {score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9998ffb799885a60661494c991679147",
     "grade": false,
     "grade_id": "cell-bebdfbe98e8010dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Score on real MNIST digits\n",
    "samples = torch.stack([testset[i][0] for i in range(10000)]).to(device)\n",
    "score = fdscore.calculate(samples)\n",
    "print(f'Score on MNIST: {score:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ac85d9d8c5eba3ee99bb50564ae4f1d",
     "grade": false,
     "grade_id": "cell-619a00b55e2632b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Training GANs\n",
    "\n",
    "We will now train a GAN. To assess the quality of the generated samples, we will use a simple scorer loaded in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "76a80ba0da69e3d29ac875b23c42ba17",
     "grade": false,
     "grade_id": "cell-f306dde125361541",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create the network\n",
    "nz = 10\n",
    "netG = Generator(nz=nz, ngf=64, nc=1)\n",
    "netD = Discriminator(nc=1, ndf=64)\n",
    "\n",
    "netD = netD.to(device)\n",
    "netG = netG.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ec6414cb4c1adc4431eac62b2e8f8eff",
     "grade": false,
     "grade_id": "cell-e5478e8a7afe65cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Implement the training loop in the cell below. The recommended hyperparameters:\n",
    "* Optimizer of the discriminator: Adam with learning rate 0.0002 and `betas=(0.5, 0.999)`\n",
    "* Optimizer of the generator:     Adam with learning rate 0.0002 and `betas=(0.5, 0.999)`\n",
    "\n",
    "Hints:\n",
    "- We will use the FD score to assess the quality of the generated samples. Your GAN should have the FD score below 10. This level can be reached after 5 epochs. Note that the score is stochastic and it can fluctuate during training. At convergence, the FD score can fluctuate in the range [3, 9].\n",
    "- You can use the following code to track the training progress. The code plots some generated images and computes the score that we use to evaluate the trained model. Note that the images fed to the scorer need to be normalized to be in the range [-1, 1].\n",
    "```python\n",
    "with torch.no_grad():\n",
    "    # Plot generated images\n",
    "    z = torch.randn(144, nz, 1, 1, device=device)\n",
    "    samples = netG(z)\n",
    "    tools.plot_generated_samples(samples)\n",
    "    \n",
    "    # Compute score\n",
    "    z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "    samples = netG(z)\n",
    "    score = fdscore.calculate(samples)\n",
    "```\n",
    "- You can track `D_real` and `D_fake` returned by function `discriminator_loss()`. When it is hard for the discriminator to separate real and fake images, their values are close to 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae914389933e3986497ab27451391731",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "# Set confirm=False if you do not want to be asked for confirmation before saving.\n",
    "if not skip_training:\n",
    "    tools.save_model(netG, '1_dcgan_g.pth', confirm=True)\n",
    "    tools.save_model(netD, '1_dcgan_d.pth', confirm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "40cc12a6e35bdd507142fe555e046e84",
     "grade": false,
     "grade_id": "cell-d7405a9598633d45",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    nz = 10\n",
    "    netG = Generator(nz=nz, ngf=64, nc=1)\n",
    "    netD = Discriminator(nc=1, ndf=64)\n",
    "\n",
    "    tools.load_model(netG, '1_dcgan_g.pth', device)\n",
    "    tools.load_model(netD, '1_dcgan_d.pth', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "96dd9d49b0c6c0379365d8a52beff292",
     "grade": false,
     "grade_id": "cell-b46c56d8c838b7b3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## GAN evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3af6a40216d030a310fab50a8e988954",
     "grade": true,
     "grade_id": "cell-e95aa3b7f714e6f9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Save generated samples (the pth-files will be submitted automatically together with your notebook)\n",
    "if not skip_training:\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(144, nz, 1, 1, device=device)\n",
    "        samples = netG(z)\n",
    "        torch.save(samples, '1_dcgan_samples.pth')\n",
    "else:\n",
    "    samples = torch.load('1_dcgan_samples.pth', map_location=lambda storage, loc: storage)\n",
    "\n",
    "tools.plot_generated_samples(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b861f66bf6a572406e1ca8d387c011dd",
     "grade": true,
     "grade_id": "test_quality",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Compute the FD score\n",
    "torch.manual_seed(0)\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(1000, nz, 1, 1, device=device)\n",
    "    samples = netG(z)\n",
    "    tools.plot_generated_samples(samples[:144])\n",
    "    score = fdscore.calculate(samples)\n",
    "\n",
    "print(f'FD score: {score:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ea9b31e0dfd137aa56d4b39623cf4b6c",
     "grade": true,
     "grade_id": "cell-23fa22d31962c3b9",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell is used for grading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "14beeebf2cbd1a52db5c5d5ce6551fe4",
     "grade": false,
     "grade_id": "cell-37c0f19da39c5c9e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion</b>\n",
    "</div>\n",
    "\n",
    "In this notebook, we learned how to train a simple GAN model for generating images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
