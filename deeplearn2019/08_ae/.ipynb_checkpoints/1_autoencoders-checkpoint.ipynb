{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b0cbe8cd2d8d0c1675d7ce737fcc9ea",
     "grade": false,
     "grade_id": "cell-e18bc7372632c56c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Number of points for this notebook:</b> 2\n",
    "<br>\n",
    "<b>Deadline:</b> April 28, 2021 (Wednesday) 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 8.1. Bottleneck autoencoders\n",
    "\n",
    "The goal of this exercise is to get familiar with bottleneck autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "65e2970339980ef7d85c3754662c4ee8",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tools\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "97fbc17672773977ee25387ca826e26b",
     "grade": false,
     "grade_id": "cell-6c689cad698955aa",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8fa17563d39bd63f3e78fbc8bef90470",
     "grade": false,
     "grade_id": "cell-1719dd29ac7b2ba6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Data\n",
    "\n",
    "In this exercise, we use the standard MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68174d3e75d41ad0727674acf1e5d87a",
     "grade": false,
     "grade_id": "cell-3a8ecca2e24ee4be",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Minmax normalization to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ca2663c186e3c9cf2ba9349cebf29d5",
     "grade": false,
     "grade_id": "cell-bc25fbf2c415bdf6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = iter(trainloader).next()\n",
    "tools.plot_images(images[:8], ncol=4, cmap=plt.cm.Greys, clim=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3c3ddea5a58dc951fb57f22b2a463f7",
     "grade": false,
     "grade_id": "cell-94867dbc5fc9c8d1",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# Train a deep autoencoder\n",
    "\n",
    "We train a deep autoencoders with only fully-connected layers.\n",
    "\n",
    "## Encoder\n",
    "\n",
    "Our encoder will have three hidden layers with ReLU nonlinearities. The exact architecture is not tested. We used the following architecture in our experiments:\n",
    "- a fully-connected layer with 1000 units followed by ReLU nonlinearity\n",
    "- a fully-connected layer with 500 units followed by ReLU nonlinearity\n",
    "- a fully-connected layer with 250 units followed by ReLU nonlinearity\n",
    "- a fully-connected layer with `n_components` outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b07ba479186a49fdc8f35cd057b4d8fa",
     "grade": false,
     "grade_id": "encoder",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, n_components):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_components (int): Number of elements in produced encodings.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, n_channels=1, width, height): Examples to encode.\n",
    "\n",
    "        Returns:\n",
    "          z of shape (batch_size, n_components): Produced encodings.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a88aa07dd09b5c78ad8f723395c085a5",
     "grade": false,
     "grade_id": "cell-77976f148263751d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_Encoder_shapes():\n",
    "    n_components = 2\n",
    "    encoder = Encoder(n_components)\n",
    "    \n",
    "    x = torch.randn(3, 1, 28, 28)\n",
    "    y = encoder(x)\n",
    "    assert y.shape == torch.Size([3, n_components]), f\"Bad y.shape: {y.shape}\"\n",
    "    print('Success')\n",
    "\n",
    "test_Encoder_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3e78b5aa9442b6e8157874f6a0956955",
     "grade": false,
     "grade_id": "cell-7984b9a53f198a03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Decoder\n",
    "\n",
    "Our decoder will have three hidden layers with ReLU nonlinearities. The exact architecture is not tested. We used the following architecture in our experiments:\n",
    "- a fully-connected layer with 250 units followed by ReLU nonlinearity\n",
    "- a fully-connected layer with 500 units followed by ReLU nonlinearity\n",
    "- a fully-connected layer with 1000 units followed by ReLU nonlinearity\n",
    "- a fully-connected layer with 784 outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b552f5b065905ea1e89494ed7f37de6",
     "grade": false,
     "grade_id": "decoder",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, n_components):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_components (int): Number of elements in input codes.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def forward(self, z):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          z of shape (batch_size, n_components): Codes to decode.\n",
    "\n",
    "        Returns:\n",
    "          xrec of shape (batch_size, n_channels=1, width, height): Reconstructions computed from the given codes.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "21739e36f522420dcab7265a66f4c182",
     "grade": false,
     "grade_id": "cell-4c0db481f14d2929",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def test_Decoder_shapes():\n",
    "    n_components = 2\n",
    "    decoder = Decoder(n_components)\n",
    "    \n",
    "    z = torch.randn(3, n_components)\n",
    "    y = decoder(z)\n",
    "    assert y.shape == torch.Size([3, 1, 28, 28]), \"Bad shape of y: y.shape={}\".format(y.shape)\n",
    "    print('Success')\n",
    "\n",
    "test_Decoder_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6caf996b78ce837c1df46071b98d22ba",
     "grade": false,
     "grade_id": "cell-c0fd59ba80034121",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Train a bottleneck autoencoder\n",
    "\n",
    "We will use the bottleneck autoencoder to encode MNIST images into 10-dimensional representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "009f1d3ec59a8682b2d50bc829a3288e",
     "grade": false,
     "grade_id": "cell-0be3aded6232563a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a deep autoencoder\n",
    "n_components = 10\n",
    "encoder = Encoder(n_components)\n",
    "encoder.to(device)\n",
    "\n",
    "decoder = Decoder(n_components)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "90bdf6745da34bfe68e4bd7412dbb0af",
     "grade": false,
     "grade_id": "cell-21e06161069d0c09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Implement the training loop in the cell below. In the training loop, the training data are first encoded into lower-dimensional representations using the encoder. Then, the decoder is used to produce the reconstructions of the original images from the lower-dimensional code. We will use the `MSELoss` to measure the reconstruction error, which is minimized during training.\n",
    "\n",
    "The recommended hyperparameters:\n",
    "* Adam optimizer with learning rate 0.001\n",
    "\n",
    "Hints:\n",
    "- Training usually converges fast, four epochs is usually enough.\n",
    "- The loss at convergence should be close to 0.066."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "faf6819518f47043935cf238a18b325a",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "# Set confirm=False if you do not want to be asked for confirmation before saving.\n",
    "if not skip_training:\n",
    "    tools.save_model(encoder, '1_ae_encoder.pth', confirm=True)\n",
    "    tools.save_model(decoder, '1_ae_decoder.pth', confirm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02d9c1e98487834c573820460bbbbfea",
     "grade": false,
     "grade_id": "cell-a87b586ffde2e123",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    encoder = Encoder(n_components=10)\n",
    "    tools.load_model(encoder, '1_ae_encoder.pth', device)\n",
    "\n",
    "    decoder = Decoder(n_components=10)\n",
    "    tools.load_model(decoder, '1_ae_decoder.pth', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae2c02dec08ad051bcc5ec1f88123f4f",
     "grade": false,
     "grade_id": "cell-33e544e3b0996c9d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Visualize embeddings\n",
    "\n",
    "Let us visualize the latent space in the cell below. If your autoencoder does a good job, you should clearly see ten clusters corresponding to the ten classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "74b4e8a72977fa4ff24710baac65563b",
     "grade": false,
     "grade_id": "cell-88a80116ab8aa4c7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tests.visualize_embeddings(encoder, trainloader, n_samples=1000, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32f93ef520e663765ea4aa59ff4c28b5",
     "grade": false,
     "grade_id": "cell-ebc5cc2c42ebe7e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Let's visualize test images and their reconstructions using the trained autoencoder\n",
    "tests.visualize_reconstructions(encoder, decoder, trainloader, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bf2a0e70f0d6c663d0a72db0fc56ab57",
     "grade": false,
     "grade_id": "cell-a2dcd9e8c0a1ae3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Test the quality of the produced embeddings by classification\n",
    "\n",
    "We will test the quality of the produced encodings by training a classifier using the encoded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fabd13eb3f68f1d86447a4977000cce",
     "grade": false,
     "grade_id": "cell-c5a8d7261f770312",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.MNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e18bb1c4df668f81183d3295894f130",
     "grade": false,
     "grade_id": "cell-41b3c545db653cc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Encode data samples using the encoder\n",
    "def encode(dataset, encoder):\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=100, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        embeddings = []\n",
    "        labels = []\n",
    "        for images, labels_ in dataloader:\n",
    "            embeddings.append(encoder(images.to(device)))\n",
    "            labels.append(labels_)\n",
    "\n",
    "        embeddings = torch.cat(embeddings, dim=0)\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "    return embeddings, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0bdc2e65a077b57af4df8c82833aa10f",
     "grade": false,
     "grade_id": "cell-8de75faacd7cdc16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Save and submit the AE embeddings\n",
    "if not skip_training:\n",
    "    traincodes, trainlabels = encode(trainset, encoder)  # traincodes is (60000, 10)\n",
    "    testcodes, testlabels = encode(testset, encoder)  # testcodes is (10000, 10)\n",
    "    torch.save([traincodes, trainlabels, testcodes, testlabels], '1_ae_embeddings.pth')\n",
    "else:\n",
    "    traincodes, trainlabels, testcodes, testlabels = torch.load('1_ae_embeddings.pth', map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8626d2ab5bfeffac4db938403f04237",
     "grade": true,
     "grade_id": "accuracy",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Train a simple linear classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression(C=1e5, solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(traincodes.cpu(), trainlabels.cpu())\n",
    "\n",
    "predicted_labels = logreg.predict(testcodes.cpu())  # (10000,)\n",
    "\n",
    "accuracy = np.sum(testlabels.cpu().numpy() == predicted_labels) / predicted_labels.size\n",
    "print('Accuracy with a linear classifier: %.2f%%' % (accuracy*100))\n",
    "assert accuracy > .85, \"Poor accuracy of the embeddings: classification accuracy is %.2f%%\" % (accuracy*100)\n",
    "print('Success')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0b446e18aed39df16e9eee616d6d6a53",
     "grade": false,
     "grade_id": "cell-e43f3ec61532406f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Conclusion</b>\n",
    "</div>\n",
    "\n",
    "In this exercise, we reduced the dimensionality of the MNIST data from $28 \\times 28 = 784$ to $10$ using a bottleneck autoecoder. Using a very simple linear classifier, we were able to classify the encoded images with a good accuracy, which is the evidence that the structure of the data is well preserved in the embedding space."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
