{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e687fbf1a28daef34da29b9250bef69f",
     "grade": false,
     "grade_id": "cell-440df6cfa709812f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Deadline:</b> March 15, 2023 (Wednesday) 23:00\n",
    "</div>\n",
    "\n",
    "# Exercise 2. Convolutional networks. VGG-style network.\n",
    "\n",
    "In the second part you need to train a convolutional neural network with an architecture inspired by a VGG-network [(Simonyan \\& Zisserman, 2015)](https://arxiv.org/abs/1409.1556)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_training = True  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9cc4d569dc32e40fe066146a07b7c7b7",
     "grade": true,
     "grade_id": "evaluation_settings",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# During evaluation, this cell sets skip_training to True\n",
    "# skip_training = True\n",
    "\n",
    "import tools, warnings\n",
    "warnings.showwarning = tools.customwarn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tools\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is /coursedata\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "48d33ffe246f5459117f53cac15b370d",
     "grade": false,
     "grade_id": "cell-fe95dcf02c6b9c5e",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2f2b11aa8f0d0377563333bd78493751",
     "grade": false,
     "grade_id": "cell-e5b565cc4aae8e7f",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "## FashionMNIST dataset\n",
    "\n",
    "Let us use the FashionMNIST dataset. It consists of 60,000 training images of 10 classes: 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d9fb758b86d03e9884930cd772a48671",
     "grade": false,
     "grade_id": "cell-8b0fded08998282c",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Scale images to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f6cde19253d8a93916505d95820bd979",
     "grade": false,
     "grade_id": "cell-4ab9d042e4edcd54",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "# VGG-style network\n",
    "\n",
    "Let us now define a convolution neural network with an architecture inspired by the [VGG-net](https://arxiv.org/abs/1409.1556).\n",
    "\n",
    "The architecture:\n",
    "- A block of three convolutional layers with:\n",
    "    - 3x3 kernel\n",
    "    - 20 output channels\n",
    "    - one pixel zero-pading on both sides\n",
    "    - 2d batch normalization after each convolutional layer\n",
    "    - ReLU nonlinearity after each 2d batch normalization layer\n",
    "- Max pooling layer with 2x2 kernel and stride 2.\n",
    "- A block of three convolutional layers with:\n",
    "    - 3x3 kernel\n",
    "    - 40 output channels\n",
    "    - one pixel zero-pading on both sides\n",
    "    - 2d batch normalization after each convolutional layer\n",
    "    - ReLU nonlinearity after each 2d batch normalization layer\n",
    "- Max pooling layer with 2x2 kernel and stride 2.\n",
    "- One convolutional layer with:\n",
    "    - 3x3 kernel\n",
    "    - 60 output channels\n",
    "    - *no padding*\n",
    "    - 2d batch normalization after the convolutional layer\n",
    "    - ReLU nonlinearity after the 2d batch normalization layer\n",
    "- One convolutional layer with:\n",
    "    - 1x1 kernel\n",
    "    - 40 output channels\n",
    "    - *no padding*\n",
    "    - 2d batch normalization after the convolutional layer\n",
    "    - ReLU nonlinearity after the 2d batch normalization layer\n",
    "- One convolutional layer with:\n",
    "    - 1x1 kernel\n",
    "    - 20 output channels\n",
    "    - *no padding*\n",
    "    - 2d batch normalization after the convolutional layer\n",
    "    - ReLU nonlinearity after the 2d batch normalization layer\n",
    "- Global average pooling (compute the average value of each channel across all the input locations):\n",
    "    - 5x5 kernel (the input of the layer should be 5x5)\n",
    "- A fully-connected layer with 10 outputs (no nonlinearity)\n",
    "\n",
    "Notes:\n",
    "* Batch normalization is expected to be right after a convolutional layer, before nonlinearity.\n",
    "* We recommend that you check the number of modules with trainable parameters in your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28866c07a4d64281f3b81ca0e16b4954",
     "grade": false,
     "grade_id": "cell-958d9ce586a51bd3",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class VGGNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGGNet, self).__init__()\n",
    "        # YOUR CODE HERE\n",
    "        # raise NotImplementedError()\n",
    "\n",
    "        # Convolutional layer\n",
    "        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, \n",
    "        # dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None)\n",
    "        \n",
    "        # Max pooling layer\n",
    "        # torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, \n",
    "        #                    return_indices=False, ceil_mode=False)\n",
    "        \n",
    "        # ReLU function\n",
    "        # torch.nn.ReLU(inplace=False)\n",
    "        \n",
    "        # Fully connected (fc) layer\n",
    "        # torch.nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "        \n",
    "        # torch.nn.BatchNorm2d(num_features, eps=1e-05, momentum=0.1, affine=True, \n",
    "        #                      track_running_stats=True, device=None, dtype=None)\n",
    "        # num_features (int) â€“ C from the 4D shape input (N, C, H, W)\n",
    "        \n",
    "        # torch.nn.AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, \n",
    "        #                    count_include_pad=True, divisor_override=None)\n",
    "        \n",
    "        # Shape of the input tensor: torch.Size([32, 1, 28, 28])\n",
    "        \n",
    "        # A block of three convolutional layers \n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(num_features=20)\n",
    "        self.relu1 = nn.ReLU()\n",
    "    \n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(num_features=20)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=20, out_channels=20, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(num_features=20)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        \n",
    "        # torch.Size([32, 20, 28, 28])\n",
    "        \n",
    "        # Max pooling layer with 2x2 kernel and stride 2\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # torch.Size([32, 20, 14, 14])\n",
    "        \n",
    "        # A block of three convolutional layers \n",
    "        self.conv4 = nn.Conv2d(in_channels=20, out_channels=40, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(num_features=40)\n",
    "        self.relu4 = nn.ReLU()\n",
    "    \n",
    "        self.conv5 = nn.Conv2d(in_channels=40, out_channels=40, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(num_features=40)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(in_channels=40, out_channels=40, kernel_size=3, stride=1, padding=1)\n",
    "        self.batchnorm6 = nn.BatchNorm2d(num_features=40)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        \n",
    "        # torch.Size([32, 40, 14, 14])\n",
    "        \n",
    "        # Max pooling layer with 2x2 kernel and stride 2\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # torch.Size([32, 40, 7, 7])\n",
    "        \n",
    "        # One convolutional layer\n",
    "        self.conv7 = nn.Conv2d(in_channels=40, out_channels=60, kernel_size=3, stride=1, padding=0)\n",
    "        self.batchnorm7 = nn.BatchNorm2d(num_features=60)\n",
    "        self.relu7 = nn.ReLU()\n",
    "\n",
    "        # torch.Size([32, 60, 5, 5])\n",
    "        \n",
    "        # One convolutional layer\n",
    "        self.conv8 = nn.Conv2d(in_channels=60, out_channels=40, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnorm8 = nn.BatchNorm2d(num_features=40)\n",
    "        self.relu8 = nn.ReLU()\n",
    "\n",
    "        # torch.Size([32, 40, 5, 5])\n",
    "        \n",
    "        # One convolutional layer\n",
    "        self.conv9 = nn.Conv2d(in_channels=40, out_channels=20, kernel_size=1, stride=1, padding=0)\n",
    "        self.batchnorm9 = nn.BatchNorm2d(num_features=20)\n",
    "        self.relu9 = nn.ReLU()\n",
    "        \n",
    "        # torch.Size([32, 20, 5, 5])\n",
    "        \n",
    "        # Global average pooling\n",
    "        self.avgpool1 = nn.AvgPool2d(kernel_size=5)\n",
    "        \n",
    "        # torch.Size([32, 20, 1, 1])\n",
    "        \n",
    "        # Flatten in the forward to turn this into the shape below\n",
    "        # torch.Size([32, 20])\n",
    "        \n",
    "        # A fully-connected layer with 10 outputs\n",
    "        self.fc1 = nn.Linear(in_features=20, out_features=10)\n",
    "        \n",
    "        # torch.Size([32, 10])\n",
    "        \n",
    "    def forward(self, x, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Input images.\n",
    "          verbose: True if you want to print the shapes of the intermediate variables.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (batch_size, 10): Outputs of the network.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        # raise NotImplementedError()\n",
    "\n",
    "        # A block of three convolutional layers \n",
    " \n",
    "        #print(x.shape)\n",
    "        \n",
    "        y = self.conv1(x)\n",
    "        y = self.batchnorm1(y)\n",
    "        y = self.relu1(y)\n",
    "    \n",
    "        y = self.conv2(y)\n",
    "        y = self.batchnorm2(y)\n",
    "        y = self.relu2(y)\n",
    "        \n",
    "        y = self.conv3(y)\n",
    "        y = self.batchnorm3(y)\n",
    "        y = self.relu3(y)\n",
    "        \n",
    "        #print(y.shape)\n",
    "        \n",
    "        # Max pooling layer with 2x2 kernel and stride 2\n",
    "        y = self.maxpool1(y)\n",
    "        \n",
    "        #print(y.shape)\n",
    "        \n",
    "        # A block of three convolutional layers \n",
    "        y = self.conv4(y)\n",
    "        y = self.batchnorm4(y)\n",
    "        y = self.relu4(y)\n",
    "    \n",
    "        y = self.conv5(y)\n",
    "        y = self.batchnorm5(y)\n",
    "        y = self.relu5(y)\n",
    "        \n",
    "        y = self.conv6(y)\n",
    "        y = self.batchnorm6(y)\n",
    "        y = self.relu6(y)\n",
    "        \n",
    "        #print(y.shape)\n",
    "\n",
    "        # Max pooling layer with 2x2 kernel and stride 2\n",
    "        y = self.maxpool2(y)\n",
    "        \n",
    "        #print(y.shape)\n",
    "        \n",
    "        # One convolutional layer\n",
    "        y = self.conv7(y)\n",
    "        y = self.batchnorm7(y)\n",
    "        y = self.relu7(y)\n",
    "\n",
    "        # One convolutional layer\n",
    "        y = self.conv8(y)\n",
    "        y = self.batchnorm8(y)\n",
    "        y = self.relu8(y)\n",
    "\n",
    "        # One convolutional layer\n",
    "        y = self.conv9(y)\n",
    "        y = self.batchnorm9(y)\n",
    "        y = self.relu9(y)\n",
    "        \n",
    "        #print(y.shape)\n",
    "        \n",
    "        # Global average pooling\n",
    "        y = self.avgpool1(y)\n",
    "        \n",
    "        #print(y.shape)\n",
    "        \n",
    "        # Flatten y\n",
    "        feature = 1\n",
    "        for size in y.size()[1:]:\n",
    "            feature *= size\n",
    "        \n",
    "        y = y.view(-1, feature)\n",
    "        \n",
    "        #print(y.shape)\n",
    "        \n",
    "        # A fully-connected layer with 10 outputs\n",
    "        y = self.fc1(y)\n",
    "        \n",
    "        #print(y.shape)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd755dd7c2d686a805e52ee83f3bcc55",
     "grade": false,
     "grade_id": "cell-e9e9a9dcda247c96",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the input tensor: torch.Size([32, 1, 28, 28])\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "def test_VGGNet_shapes():\n",
    "    net = VGGNet()\n",
    "    net.to(device)\n",
    "\n",
    "    # Feed a batch of images from the training data to test the network\n",
    "    with torch.no_grad():\n",
    "        images, labels = next(iter(trainloader))\n",
    "        images = images.to(device)\n",
    "        print('Shape of the input tensor:', images.shape)\n",
    "\n",
    "        y = net(images, verbose=True)\n",
    "        assert y.shape == torch.Size([trainloader.batch_size, 10]), f\"Bad y.shape: {y.shape}\"\n",
    "\n",
    "    print('Success')\n",
    "\n",
    "test_VGGNet_shapes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6e811990eff00e343bd66bac478b3513",
     "grade": true,
     "grade_id": "test_VGGNet",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success\n",
      "[(10,), (10, 20), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20, 1, 3, 3), (20, 20, 3, 3), (20, 20, 3, 3), (20, 40, 1, 1), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40, 20, 3, 3), (40, 40, 3, 3), (40, 40, 3, 3), (40, 60, 1, 1), (60,), (60,), (60,), (60, 40, 3, 3)]\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Check the number of layers\n",
    "def test_vgg_layers():\n",
    "    net = VGGNet()\n",
    "    \n",
    "    # get gradients for parameters in forward path\n",
    "    net.zero_grad()\n",
    "    x = torch.randn(1, 1, 28, 28)\n",
    "    outputs = net(x)\n",
    "    outputs[0,0].backward()\n",
    "\n",
    "    n_conv_layers = sum(1 for module in net.modules()\n",
    "                        if isinstance(module, nn.Conv2d) and next(module.parameters()).grad is not None)\n",
    "    assert n_conv_layers == 9, f\"Wrong number of convolutional layers ({n_conv_layers})\"\n",
    "\n",
    "    n_bn_layers = sum(1 for module in net.modules()\n",
    "                      if isinstance(module, nn.BatchNorm2d) and next(module.parameters()).grad is not None)\n",
    "    assert n_bn_layers == 9, f\"Wrong number of batch norm layers ({n_bn_layers})\"\n",
    "\n",
    "    n_linear_layers = sum(1 for module in net.modules()\n",
    "                          if isinstance(module, nn.Linear) and next(module.parameters()).grad is not None)\n",
    "    assert n_linear_layers == 1, f\"Wrong number of linear layers ({n_linear_layers})\"\n",
    "\n",
    "    print('Success')\n",
    "\n",
    "def test_vgg_net():\n",
    "    net = VGGNet()\n",
    "    \n",
    "    # get gradients for parameters in forward path\n",
    "    net.zero_grad()\n",
    "    x = torch.randn(1, 1, 28, 28)\n",
    "    outputs = net(x)\n",
    "    outputs[0,0].backward()\n",
    "    \n",
    "    parameter_shapes = sorted(tuple(p.shape) for p in net.parameters() if p.grad is not None)\n",
    "    print(parameter_shapes)\n",
    "    expected = [\n",
    "        (10,), (10, 20), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,), (20,),\n",
    "        (20,), (20,), (20,), (20, 1, 3, 3), (20, 20, 3, 3), (20, 20, 3, 3), (20, 40, 1, 1),\n",
    "        (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,), (40,),\n",
    "        (40, 20, 3, 3), (40, 40, 3, 3), (40, 40, 3, 3), (40, 60, 1, 1), (60,), (60,), (60,),\n",
    "        (60, 40, 3, 3)]\n",
    "    assert parameter_shapes == expected, \"Wrong number of training parameters.\"\n",
    "    \n",
    "    print('Success')\n",
    "\n",
    "test_vgg_layers()\n",
    "test_vgg_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c87ccb8eb839f919438ec33b6d8f5e3b",
     "grade": false,
     "grade_id": "cell-6c5c6ddc6d0312e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f83e3828402226248c665aa6b1f49a8",
     "grade": false,
     "grade_id": "cell-9e3a0480727aec61",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "70e1b87d5ab693181bbc4ecfc21b26c8",
     "grade": false,
     "grade_id": "cell-d168751b85ea2490",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Your task is to implement the training loop. The recommended hyperparameters:\n",
    "* Adam optimizer with learning rate 0.01.\n",
    "* Cross-entropy loss. Note that we did not use softmax nonlinearity in the final layer of our network. Therefore, we need to use a loss function with log_softmax implemented, such as [nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html#torch.nn.CrossEntropyLoss).\n",
    "* Number of epochs: 10\n",
    "\n",
    "We recommend you to use function `compute_accuracy()` defined above to track the accaracy during training. The test accuracy should be above 0.89.\n",
    "\n",
    "**Note: function `compute_accuracy()` sets the network into the evaluation mode which changes the way the batch statistics are computed in batch normalization. You need to set the network into the training mode (by calling `net.train()`) when you want to perform training.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "db3a9615921b7a80d333475aa66ae69b",
     "grade": false,
     "grade_id": "cell-d5bf19391acb3661",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "net = VGGNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6270848f5387bf01aba9bb5f50303a78",
     "grade": false,
     "grade_id": "training_loop",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Implement the training loop in this cell\n",
    "if not skip_training:\n",
    "    # YOUR CODE HERE\n",
    "    #raise NotImplementedError()\n",
    "\n",
    "    # Zero out the gradients\n",
    "    net.zero_grad()\n",
    "    \n",
    "    # The loss function\n",
    "    crossEntropyLoss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # The optimizers\n",
    "    optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "    \n",
    "    # Number of training epochs \n",
    "    epochs = 10\n",
    "    \n",
    "    # Training over the dataset multiple times\n",
    "    for epoch in range(epochs):\n",
    "        # Before training the network, we call net.train() \n",
    "        net.train()\n",
    "        for images, labels in trainloader:\n",
    "            optimizer.zero_grad()\n",
    "            labels_pred = net(images)\n",
    "            loss = crossEntropyLoss(labels_pred, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        accuracy = compute_accuracy(net,testloader)\n",
    "        print(f\"Accuracy at epoch {epoch}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to disk (the pth-files will be submitted automatically together with your notebook)\n",
    "# Set confirm=False if you do not want to be asked for confirmation before saving.\n",
    "if not skip_training:\n",
    "    tools.save_model(net, '2_vgg_net.pth', confirm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4fb57a1a2e5a8cd05e115cf98ed7635a",
     "grade": false,
     "grade_id": "cell-28a73d35f35e73c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from 2_vgg_net.pth.\n"
     ]
    }
   ],
   "source": [
    "if skip_training:\n",
    "    net = VGGNet()\n",
    "    tools.load_model(net, '2_vgg_net.pth', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "63bba11d24ab5d7fd716a8930b4f1bc8",
     "grade": true,
     "grade_id": "accuracy",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the VGG net on the test images:  0.913\n",
      "Success\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy on the test set\n",
    "accuracy = compute_accuracy(net, testloader)\n",
    "print(f'Accuracy of the VGG net on the test images: {accuracy: .3f}')\n",
    "assert accuracy > 0.89, 'Poor accuracy'\n",
    "print('Success')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
